{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# テキストデータの入手・変数への格納\n",
        "\n",
        "  * 夏目漱石の「吾輩は猫である」（青空文庫）を利用\n",
        "  * requestによりWebアクセス\n",
        "\n",
        "  * bs4(Beautiful Soup)のHTML parserを利用して解析"
      ],
      "metadata": {
        "id": "aDNE_HtUqJRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests, bs4"
      ],
      "metadata": {
        "id": "Crmb9dQeqNHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(\"https://www.aozora.gr.jp/cards/000148/files/789_14547.html\")"
      ],
      "metadata": {
        "id": "e_TpoDv1rLkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup = bs4.BeautifulSoup(response.content, \"html.parser\")"
      ],
      "metadata": {
        "id": "Oi1RsTWorXbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "elems = soup.select(\".main_text\")"
      ],
      "metadata": {
        "id": "qVjYmyR4rjGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(elems)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W95eQMVEszWO",
        "outputId": "c92a3ed5-44c3-4322-97d9-463f10d19f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bs4.element.ResultSet"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = ''.join([elm.text for elm in elems])"
      ],
      "metadata": {
        "id": "zAOti1NBruFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "W0dGbYXssfAh",
        "outputId": "b7722af4-cf4a-420a-eee2-319326c6acec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n一\\n\\r\\n\\u3000吾輩は猫である。名前はまだ無い。\\r\\n\\u3000どこで生れたかとんと見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。しかもあとで聞くとそれは書生という人間中で一番獰悪な種族であったそうだ。この書生というのは時々我々を捕えて煮て食うという話である。しかしその当時は何という考もなかったから別段恐しいとも思わなかった。ただ彼の掌に載せられてスーと持ち上げられた時何だかフワフワした感じがあったばかりである。掌の上で少し落ちついて書生の顔を見たのがいわゆる人間というものの見始であろう。この時妙なものだと思った感じが今でも残っている。第一毛をもって装飾されべきはずの顔がつるつるしてまるで薬缶だ。その後猫にもだいぶ逢ったがこんな片輪には一度も出会わした事がない。のみならず顔の真中があまりに突起している。そうしてその穴の中から時々ぷうぷうと煙を吹く。どうも咽せぽくて実に弱った。これが人間の飲む煙草というものである事はようやくこの頃知った。\\r\\n\\u3000この書生の掌の裏でしばらくはよい心持に坐っておったが、しばらくすると非常な速力で運転し始めた。書生が動くのか自分だけが動くのか分らないが無暗に眼が廻る。胸が悪くなる。到底助からないと思っていると、どさりと音がして眼から火が出た。それまでは記憶しているがあとは何の事やらいくら考え出そうとしても分らない。\\r\\n\\u3000ふと気が付いて見ると書生はいない。たくさんおった兄弟が一疋も見えぬ。肝心の母親さえ姿を隠してしまった。その上今までの所とは違って無暗に明るい。眼を明いていられぬくらいだ。はてな何でも容子がおかしいと、のそのそ這い出して見ると非常に痛い。吾輩は藁の上から急に笹原の中へ棄てられたのである。\\r\\n\\u3000ようやくの思いで笹原を這い出すと向うに大きな池がある。吾輩は池の前に坐ってどうしたらよかろうと考えて見た。別にこれという分別も出ない。しばらくして泣いたら書生がまた迎に来てくれるかと考え付いた。ニャー、ニャーと試みにやって見たが誰も来ない。そのうち池の上をさらさらと風が渡って日が暮れかかる。腹が非常に減って来た。泣きたくても声が出ない。仕方がない、何でもよいから食物のある所まであるこうと決心をしてそろりそろりと池を左りに廻り始めた。どうも非常に苦しい。そこを我慢して無理やりに'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 前処理\n",
        "\n",
        "* reを利用し、改行コード（\\n一\\n, \\r\\n, \\n)と\\u3000(全角スペース)の削除\n",
        "* janomeを利用し、すべてカタカナ変換する\n",
        "* jaconvを利用し、カタカナ→ひらがな変換する\n"
      ],
      "metadata": {
        "id": "KXD86ciRxCGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install janome\n",
        "!pip install jaconv"
      ],
      "metadata": {
        "id": "WDLtLp9AyZzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250999ad-a094-4dc9-f5f6-bc66bb42ca9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting janome\n",
            "  Downloading Janome-0.5.0-py2.py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: janome\n",
            "Successfully installed janome-0.5.0\n",
            "Collecting jaconv\n",
            "  Downloading jaconv-0.3.4.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: jaconv\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.3.4-py3-none-any.whl size=16416 sha256=cc66f4d53eec13ff33408bc7cf776520eb0ba201155d120dbe104e13d3d0bd94\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/8f/2e/a730bf1fca05b33e532d5d91dabdf406c9b718ec85b01b1b54\n",
            "Successfully built jaconv\n",
            "Installing collected packages: jaconv\n",
            "Successfully installed jaconv-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "start_idx = int(len(texts) * random.random())\n",
        "end_idx = start_idx + 1000\n",
        "\n",
        "texts[start_idx:end_idx]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "6TY1p60yvv0A",
        "outputId": "80020d99-1baa-4d74-8b68-45809af39b1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'尻の重いために破れたのではない、本人の弁解によると近頃自転車の稽古を始めて局部に比較的多くの摩擦を与えるからである。未来の細君をもって矚目された本人へ文をつけた恋の仇とは夢にも知らず、「やあ」と云って武右衛門君に軽く会釈をして椽側へ近い所へ座をしめた。\\r\\n「虎の鳴き声を聞いたって詰らないじゃないか」\\r\\n「ええ、今じゃいけません、これから方々散歩して夜十一時頃になって、上野へ行くんです」\\r\\n「へえ」\\r\\n「すると公園内の老木は森々として物凄いでしょう」\\r\\n「そうさな、昼間より少しは淋しいだろう」\\r\\n「それで何でもなるべく樹の茂った、昼でも人の通らない所を択ってあるいていると、いつの間にか紅塵万丈の都会に住んでる気はなくなって、山の中へ迷い込んだような心持ちになるに相違ないです」\\r\\n「そんな心持ちになってどうするんだい」\\r\\n「そんな心持ちになって、しばらく佇んでいるとたちまち動物園のうちで、虎が鳴くんです」\\r\\n「そう旨く鳴くかい」\\r\\n「大丈夫鳴きます。あの鳴き声は昼でも理科大学へ聞えるくらいなんですから、深夜闃寂として、四望人なく、鬼気肌に逼って、魑魅鼻を衝く際に……」\\r\\n「魑魅鼻を衝くとは何の事だい」\\r\\n「そんな事を云うじゃありませんか、怖い時に」\\r\\n「そうかな。あんまり聞かないようだが。それで」\\r\\n「それで虎が上野の老杉の葉をことごとく振い落すような勢で鳴くでしょう。物凄いでさあ」\\r\\n「そりゃ物凄いだろう」\\r\\n「どうです冒険に出掛けませんか。きっと愉快だろうと思うんです。どうしても虎の鳴き声は夜なかに聞かなくっちゃ、聞いたとはいわれないだろうと思うんです」\\r\\n「そうさな」と主人は武右衛門君の哀願に冷淡であるごとく、寒月君の探検にも冷淡である。\\r\\n\\u3000この時まで黙然として虎の話を羨ましそうに聞いていた武右衛門君は主人の「そうさな」で再び自分の身の上を思い出したと見えて、「先生、僕は心配なんですが、どうしたらいいでしょう」とまた聞き返す。寒月君は不審な顔をしてこの大きな頭を見た。吾輩は思う仔細あってちょっと失敬して茶の間へ廻る。\\r\\n\\u3000茶の間では細君がくすくす笑いながら、京焼の安茶碗に番茶を浪々と注いで、アンチモニーの茶托の上へ載せて、\\r\\n「雪江さん、憚りさま、これを出して来て下さい」\\r\\n「わたし、いやよ」\\r\\n「どうして」と細君は少々驚ろいた体で笑いをはたと留める。\\r\\n「どう'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:1000]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "VVtbftH3v8Qm",
        "outputId": "82387139-26e7-44b3-aeee-77f8d295db89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n一\\n\\r\\n\\u3000吾輩は猫である。名前はまだ無い。\\r\\n\\u3000どこで生れたかとんと見当がつかぬ。何でも薄暗いじめじめした所でニャーニャー泣いていた事だけは記憶している。吾輩はここで始めて人間というものを見た。しかもあとで聞くとそれは書生という人間中で一番獰悪な種族であったそうだ。この書生というのは時々我々を捕えて煮て食うという話である。しかしその当時は何という考もなかったから別段恐しいとも思わなかった。ただ彼の掌に載せられてスーと持ち上げられた時何だかフワフワした感じがあったばかりである。掌の上で少し落ちついて書生の顔を見たのがいわゆる人間というものの見始であろう。この時妙なものだと思った感じが今でも残っている。第一毛をもって装飾されべきはずの顔がつるつるしてまるで薬缶だ。その後猫にもだいぶ逢ったがこんな片輪には一度も出会わした事がない。のみならず顔の真中があまりに突起している。そうしてその穴の中から時々ぷうぷうと煙を吹く。どうも咽せぽくて実に弱った。これが人間の飲む煙草というものである事はようやくこの頃知った。\\r\\n\\u3000この書生の掌の裏でしばらくはよい心持に坐っておったが、しばらくすると非常な速力で運転し始めた。書生が動くのか自分だけが動くのか分らないが無暗に眼が廻る。胸が悪くなる。到底助からないと思っていると、どさりと音がして眼から火が出た。それまでは記憶しているがあとは何の事やらいくら考え出そうとしても分らない。\\r\\n\\u3000ふと気が付いて見ると書生はいない。たくさんおった兄弟が一疋も見えぬ。肝心の母親さえ姿を隠してしまった。その上今までの所とは違って無暗に明るい。眼を明いていられぬくらいだ。はてな何でも容子がおかしいと、のそのそ這い出して見ると非常に痛い。吾輩は藁の上から急に笹原の中へ棄てられたのである。\\r\\n\\u3000ようやくの思いで笹原を這い出すと向うに大きな池がある。吾輩は池の前に坐ってどうしたらよかろうと考えて見た。別にこれという分別も出ない。しばらくして泣いたら書生がまた迎に来てくれるかと考え付いた。ニャー、ニャーと試みにやって見たが誰も来ない。そのうち池の上をさらさらと風が渡って日が暮れかかる。腹が非常に減って来た。泣きたくても声が出ない。仕方がない、何でもよいから食物のある所まであるこうと決心をしてそろりそろりと池を左りに廻り始めた。どうも非常に苦しい。そこを我慢して無理やりに'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "pattern = re.compile(r\"\\n一\\n|\\r\\n|\\n|\\u3000\", re.MULTILINE | re.DOTALL)\n",
        "\n",
        "texts = re.sub(pattern, \"\", texts)"
      ],
      "metadata": {
        "id": "m9dAXeBiwxiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from janome.tokenizer import Tokenizer\n",
        "import jaconv\n",
        "\n",
        "def get_yomigana(original_txt):\n",
        "  t = Tokenizer()\n",
        "  l = []\n",
        "  for w in t.tokenize(original_txt):\n",
        "    reading = w.reading\n",
        "    if  reading == '*':\n",
        "      l.append(w.base_form)\n",
        "    else:\n",
        "      l.append(reading)\n",
        "  hira = jaconv.kata2hira(''.join(l))\n",
        "  return hira"
      ],
      "metadata": {
        "id": "_lqK2FV53B7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_yomigana(\"現在、気温が40度近くです。\")"
      ],
      "metadata": {
        "id": "Xo941m3t3DqJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "e4c43618-e673-40cc-d8f6-e11db343ea5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'げんざい、きおんが40どちかくです。'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# エンコーディング\n",
        "\n",
        "## テキストを索引（インデックス）のリストに変換すること\n",
        "\n",
        "* ユニークな文字を取得し、それぞれにインデックスを割り当てる\n",
        "\n",
        "* 任意のテキストをエンコーディングする\n",
        "\n",
        "* 吾輩は猫であるの文字種を取得し、それぞれにインデックスを割り当てる\n",
        "\n",
        "* 吾輩は猫であるをエンコーディングする"
      ],
      "metadata": {
        "id": "empWs4GtGgK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = get_yomigana(texts)"
      ],
      "metadata": {
        "id": "PmKQ2Hin_KSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(txt):\n",
        "  ctoi = {c:i for (i, c) in enumerate(sorted(set(texts)))}\n",
        "  return [ctoi[c] for c in txt]\n",
        "encoded_txt = encode(texts)"
      ],
      "metadata": {
        "id": "xemUqa7z9grB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_txt"
      ],
      "metadata": {
        "id": "r0_UvhLe_bMw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d024ced6-301e-40df-81be-97fb6e6d6316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[126,\n",
              " 60,\n",
              " 95,\n",
              " 53,\n",
              " 95,\n",
              " 93,\n",
              " 67,\n",
              " 87,\n",
              " 51,\n",
              " 123,\n",
              " 44,\n",
              " 90,\n",
              " 110,\n",
              " 56,\n",
              " 95,\n",
              " 110,\n",
              " 80,\n",
              " 90,\n",
              " 53,\n",
              " 44,\n",
              " 89,\n",
              " 67,\n",
              " 87,\n",
              " 54,\n",
              " 110,\n",
              " 124,\n",
              " 79,\n",
              " 59,\n",
              " 88,\n",
              " 128,\n",
              " 88,\n",
              " 65,\n",
              " 128,\n",
              " 88,\n",
              " 54,\n",
              " 60,\n",
              " 84,\n",
              " 59,\n",
              " 92,\n",
              " 44,\n",
              " 90,\n",
              " 91,\n",
              " 87,\n",
              " 114,\n",
              " 54,\n",
              " 73,\n",
              " 64,\n",
              " 121,\n",
              " 53,\n",
              " 72,\n",
              " 113,\n",
              " 72,\n",
              " 113,\n",
              " 71,\n",
              " 79,\n",
              " 88,\n",
              " 67,\n",
              " 125,\n",
              " 87,\n",
              " 91,\n",
              " 115,\n",
              " 131,\n",
              " 91,\n",
              " 115,\n",
              " 131,\n",
              " 90,\n",
              " 53,\n",
              " 86,\n",
              " 53,\n",
              " 79,\n",
              " 67,\n",
              " 88,\n",
              " 80,\n",
              " 65,\n",
              " 95,\n",
              " 61,\n",
              " 58,\n",
              " 63,\n",
              " 71,\n",
              " 86,\n",
              " 53,\n",
              " 123,\n",
              " 44,\n",
              " 126,\n",
              " 60,\n",
              " 95,\n",
              " 53,\n",
              " 95,\n",
              " 67,\n",
              " 67,\n",
              " 87,\n",
              " 95,\n",
              " 72,\n",
              " 113,\n",
              " 86,\n",
              " 91,\n",
              " 128,\n",
              " 66,\n",
              " 128,\n",
              " 88,\n",
              " 53,\n",
              " 54,\n",
              " 114,\n",
              " 94,\n",
              " 127,\n",
              " 111,\n",
              " 79,\n",
              " 44,\n",
              " 71,\n",
              " 59,\n",
              " 114,\n",
              " 51,\n",
              " 88,\n",
              " 87,\n",
              " 61,\n",
              " 63,\n",
              " 88,\n",
              " 77,\n",
              " 124,\n",
              " 95,\n",
              " 71,\n",
              " 119,\n",
              " 75,\n",
              " 53,\n",
              " 88,\n",
              " 53,\n",
              " 54,\n",
              " 91,\n",
              " 128,\n",
              " 66,\n",
              " 128,\n",
              " 81,\n",
              " 117,\n",
              " 54,\n",
              " 87,\n",
              " 53,\n",
              " 81,\n",
              " 96,\n",
              " 128,\n",
              " 89,\n",
              " 54,\n",
              " 51,\n",
              " 63,\n",
              " 90,\n",
              " 71,\n",
              " 117,\n",
              " 78,\n",
              " 63,\n",
              " 87,\n",
              " 51,\n",
              " 83,\n",
              " 79,\n",
              " 77,\n",
              " 54,\n",
              " 80,\n",
              " 44,\n",
              " 67,\n",
              " 94,\n",
              " 71,\n",
              " 119,\n",
              " 75,\n",
              " 53,\n",
              " 88,\n",
              " 53,\n",
              " 54,\n",
              " 94,\n",
              " 95,\n",
              " 88,\n",
              " 61,\n",
              " 89,\n",
              " 61,\n",
              " 126,\n",
              " 124,\n",
              " 126,\n",
              " 124,\n",
              " 127,\n",
              " 88,\n",
              " 121,\n",
              " 56,\n",
              " 86,\n",
              " 91,\n",
              " 86,\n",
              " 63,\n",
              " 54,\n",
              " 88,\n",
              " 53,\n",
              " 54,\n",
              " 95,\n",
              " 90,\n",
              " 71,\n",
              " 87,\n",
              " 51,\n",
              " 123,\n",
              " 44,\n",
              " 71,\n",
              " 59,\n",
              " 71,\n",
              " 77,\n",
              " 94,\n",
              " 88,\n",
              " 54,\n",
              " 72,\n",
              " 95,\n",
              " 90,\n",
              " 91,\n",
              " 88,\n",
              " 53,\n",
              " 54,\n",
              " 67,\n",
              " 54,\n",
              " 114,\n",
              " 90,\n",
              " 59,\n",
              " 83,\n",
              " 79,\n",
              " 59,\n",
              " 121,\n",
              " 105,\n",
              " 84,\n",
              " 80,\n",
              " 128,\n",
              " 67,\n",
              " 126,\n",
              " 71,\n",
              " 53,\n",
              " 88,\n",
              " 114,\n",
              " 58,\n",
              " 114,\n",
              " 126,\n",
              " 90,\n",
              " 59,\n",
              " 83,\n",
              " 79,\n",
              " 44,\n",
              " 79,\n",
              " 80,\n",
              " 59,\n",
              " 124,\n",
              " 94,\n",
              " 86,\n",
              " 94,\n",
              " 98,\n",
              " 121,\n",
              " 91,\n",
              " 94,\n",
              " 75,\n",
              " 121,\n",
              " 124,\n",
              " 86,\n",
              " 73,\n",
              " 131,\n",
              " 88,\n",
              " 114,\n",
              " 81,\n",
              " 51,\n",
              " 66,\n",
              " 121,\n",
              " 124,\n",
              " 79,\n",
              " 88,\n",
              " 61,\n",
              " 90,\n",
              " 128,\n",
              " 80,\n",
              " 59,\n",
              " 101,\n",
              " 126,\n",
              " 101,\n",
              " 126,\n",
              " 71,\n",
              " 79,\n",
              " 59,\n",
              " 128,\n",
              " 72,\n",
              " 60,\n",
              " 51,\n",
              " 83,\n",
              " 79,\n",
              " 96,\n",
              " 59,\n",
              " 122,\n",
              " 87,\n",
              " 51,\n",
              " 123,\n",
              " 44,\n",
              " 86,\n",
              " 94,\n",
              " 98,\n",
              " 121,\n",
              " 94,\n",
              " 54,\n",
              " 56,\n",
              " 87,\n",
              " 73,\n",
              " 67,\n",
              " 71,\n",
              " 58,\n",
              " 81,\n",
              " 84,\n",
              " 53,\n",
              " 86,\n",
              " 71,\n",
              " 119,\n",
              " 75,\n",
              " 53,\n",
              " 94,\n",
              " 59,\n",
              " 58,\n",
              " 127,\n",
              " 111,\n",
              " 79,\n",
              " 94,\n",
              " 60,\n",
              " 53,\n",
              " 126,\n",
              " 118,\n",
              " 123,\n",
              " 91,\n",
              " 128,\n",
              " 66,\n",
              " 128,\n",
              " 88,\n",
              " 53,\n",
              " 54,\n",
              " 114,\n",
              " 94,\n",
              " 94,\n",
              " 111,\n",
              " 95,\n",
              " 72,\n",
              " 113,\n",
              " 87,\n",
              " 51,\n",
              " 125,\n",
              " 54,\n",
              " 44,\n",
              " 67,\n",
              " 94,\n",
              " 88,\n",
              " 61,\n",
              " 111,\n",
              " 119,\n",
              " 54,\n",
              " 90,\n",
              " 114,\n",
              " 94,\n",
              " 80,\n",
              " 88,\n",
              " 58,\n",
              " 114,\n",
              " 83,\n",
              " 79,\n",
              " 59,\n",
              " 128,\n",
              " 72,\n",
              " 60,\n",
              " 53,\n",
              " 110,\n",
              " 87,\n",
              " 114,\n",
              " 94,\n",
              " 67,\n",
              " 83,\n",
              " 86,\n",
              " 53,\n",
              " 123,\n",
              " 44,\n",
              " 80,\n",
              " 53,\n",
              " 53,\n",
              " 81,\n",
              " 114,\n",
              " 54,\n",
              " 127,\n",
              " 114,\n",
              " 83,\n",
              " 86,\n",
              " 77,\n",
              " 54,\n",
              " 71,\n",
              " 119,\n",
              " 63,\n",
              " 69,\n",
              " 124,\n",
              " 105,\n",
              " 61,\n",
              " 95,\n",
              " 74,\n",
              " 94,\n",
              " 59,\n",
              " 58,\n",
              " 60,\n",
              " 84,\n",
              " 123,\n",
              " 84,\n",
              " 123,\n",
              " 71,\n",
              " 86,\n",
              " 110,\n",
              " 123,\n",
              " 87,\n",
              " 116,\n",
              " 59,\n",
              " 128,\n",
              " 80,\n",
              " 44,\n",
              " 77,\n",
              " 94,\n",
              " 68,\n",
              " 93,\n",
              " 67,\n",
              " 91,\n",
              " 114,\n",
              " 80,\n",
              " 53,\n",
              " 102,\n",
              " 51,\n",
              " 83,\n",
              " 79,\n",
              " 60,\n",
              " 67,\n",
              " 128,\n",
              " 90,\n",
              " 59,\n",
              " 79,\n",
              " 126,\n",
              " 91,\n",
              " 95,\n",
              " 53,\n",
              " 81,\n",
              " 89,\n",
              " 114,\n",
              " 87,\n",
              " 51,\n",
              " 126,\n",
              " 71,\n",
              " 79,\n",
              " 67,\n",
              " 88,\n",
              " 60,\n",
              " 90,\n",
              " 53,\n",
              " 44,\n",
              " 94,\n",
              " 111,\n",
              " 90,\n",
              " 121,\n",
              " 74,\n",
              " 59,\n",
              " 58,\n",
              " 94,\n",
              " 110,\n",
              " 128,\n",
              " 90,\n",
              " 59,\n",
              " 60,\n",
              " 51,\n",
              " 110,\n",
              " 122,\n",
              " 91,\n",
              " 88,\n",
              " 83,\n",
              " 61,\n",
              " 71,\n",
              " 86,\n",
              " 53,\n",
              " 123,\n",
              " 44,\n",
              " 77,\n",
              " 54,\n",
              " 71,\n",
              " 86,\n",
              " 77,\n",
              " 94,\n",
              " 51,\n",
              " 90,\n",
              " 94,\n",
              " 90,\n",
              " 59,\n",
              " 59,\n",
              " 121,\n",
              " 88,\n",
              " 61,\n",
              " 89,\n",
              " 61,\n",
              " 103,\n",
              " 54,\n",
              " 103,\n",
              " 54,\n",
              " 88,\n",
              " 65,\n",
              " 112,\n",
              " 122,\n",
              " 127,\n",
              " 101,\n",
              " 63,\n",
              " 44,\n",
              " 89,\n",
              " 54,\n",
              " 114,\n",
              " 94,\n",
              " 128,\n",
              " 89,\n",
              " 75,\n",
              " 109,\n",
              " 63,\n",
              " 86,\n",
              " 72,\n",
              " 84,\n",
              " 91,\n",
              " 120,\n",
              " 126,\n",
              " 83,\n",
              " 79,\n",
              " 44,\n",
              " 67,\n",
              " 124,\n",
              " 60,\n",
              " 91,\n",
              " 128,\n",
              " 66,\n",
              " 128,\n",
              " 94,\n",
              " 94,\n",
              " 112,\n",
              " 79,\n",
              " 96,\n",
              " 67,\n",
              " 88,\n",
              " 53,\n",
              " 54,\n",
              " 114,\n",
              " 94,\n",
              " 87,\n",
              " 51,\n",
              " 123,\n",
              " 67,\n",
              " 88,\n",
              " 95,\n",
              " 120,\n",
              " 54,\n",
              " 116,\n",
              " 63,\n",
              " 67,\n",
              " 94,\n",
              " 67,\n",
              " 125,\n",
              " 71,\n",
              " 83,\n",
              " 79,\n",
              " 44,\n",
              " 67,\n",
              " 94,\n",
              " 71,\n",
              " 119,\n",
              " 75,\n",
              " 53,\n",
              " 94,\n",
              " 86,\n",
              " 94,\n",
              " 98,\n",
              " 121,\n",
              " 94,\n",
              " 54,\n",
              " 121,\n",
              " 87,\n",
              " 71,\n",
              " 96,\n",
              " 121,\n",
              " 63,\n",
              " 95,\n",
              " 120,\n",
              " 53,\n",
              " 67,\n",
              " 67,\n",
              " 125,\n",
              " 114,\n",
              " 81,\n",
              " 91,\n",
              " 73,\n",
              " 126,\n",
              " 83,\n",
              " 86,\n",
              " 58,\n",
              " 83,\n",
              " 79,\n",
              " 60,\n",
              " 43,\n",
              " 71,\n",
              " 96,\n",
              " 121,\n",
              " 63,\n",
              " 73,\n",
              " 123,\n",
              " 88,\n",
              " 98,\n",
              " 72,\n",
              " 119,\n",
              " 54,\n",
              " 90,\n",
              " 77,\n",
              " 63,\n",
              " 122,\n",
              " 119,\n",
              " 63,\n",
              " 87,\n",
              " 54,\n",
              " 128,\n",
              " 86,\n",
              " 128,\n",
              " 71,\n",
              " 95,\n",
              " 72,\n",
              " 113,\n",
              " 79,\n",
              " 44,\n",
              " 71,\n",
              " 119,\n",
              " 75,\n",
              " 53,\n",
              " 60,\n",
              " 54,\n",
              " 68,\n",
              " 63,\n",
              " 94,\n",
              " 59,\n",
              " 72,\n",
              " 102,\n",
              " 128,\n",
              " 80,\n",
              " 65,\n",
              " 60,\n",
              " 54,\n",
              " 68,\n",
              " 63,\n",
              " 94,\n",
              " 59,\n",
              " 126,\n",
              " 59,\n",
              " 121,\n",
              " 90,\n",
              " 53,\n",
              " 60,\n",
              " 112,\n",
              " 51,\n",
              " 128,\n",
              " 91,\n",
              " 113,\n",
              " 60,\n",
              " 113,\n",
              " 64,\n",
              " 123,\n",
              " 44,\n",
              " 112,\n",
              " 93,\n",
              " 60,\n",
              " 126,\n",
              " 123,\n",
              " 63,\n",
              " 90,\n",
              " 123,\n",
              " 44,\n",
              " 88,\n",
              " 54,\n",
              " 86,\n",
              " 53,\n",
              " 79,\n",
              " 73,\n",
              " 59,\n",
              " 121,\n",
              " 90,\n",
              " 53,\n",
              " 88,\n",
              " 58,\n",
              " 114,\n",
              " 83,\n",
              " 86,\n",
              " 53,\n",
              " 123,\n",
              " 88,\n",
              " 43,\n",
              " 89,\n",
              " 69,\n",
              " 122,\n",
              " 88,\n",
              " 58,\n",
              " 88,\n",
              " 60,\n",
              " 71,\n",
              " 86,\n",
              " 113,\n",
              " 59,\n",
              " 121,\n",
              " 98,\n",
              " 60,\n",
              " 87,\n",
              " 79,\n",
              " 44,\n",
              " 77,\n",
              " 124,\n",
              " 110,\n",
              " 87,\n",
              " 95,\n",
              " 61,\n",
              " 58,\n",
              " 63,\n",
              " 71,\n",
              " 86,\n",
              " 53,\n",
              " 123,\n",
              " 60,\n",
              " 51,\n",
              " 88,\n",
              " 95,\n",
              " 90,\n",
              " 91,\n",
              " 94,\n",
              " 67,\n",
              " 88,\n",
              " 116,\n",
              " 121,\n",
              " 53,\n",
              " 63,\n",
              " 121,\n",
              " 59,\n",
              " 128,\n",
              " 60,\n",
              " 56,\n",
              " 80,\n",
              " 77,\n",
              " 54,\n",
              " 88,\n",
              " 71,\n",
              " 86,\n",
              " 114,\n",
              " 126,\n",
              " 59,\n",
              " 121,\n",
              " 90,\n",
              " 53,\n",
              " 44,\n",
              " 101,\n",
              " 88,\n",
              " 61,\n",
              " 60,\n",
              " 84,\n",
              " 53,\n",
              " 86,\n",
              " 111,\n",
              " 123,\n",
              " 88,\n",
              " 71,\n",
              " 119,\n",
              " 75,\n",
              " 53,\n",
              " 95,\n",
              " 53,\n",
              " 90,\n",
              " 53,\n",
              " 44,\n",
              " 79,\n",
              " 63,\n",
              " 69,\n",
              " 128,\n",
              " 58,\n",
              " 83,\n",
              " 79,\n",
              " 61,\n",
              " 119,\n",
              " 54,\n",
              " 80,\n",
              " 53,\n",
              " 60,\n",
              " 53,\n",
              " 83,\n",
              " 100,\n",
              " 61,\n",
              " 114,\n",
              " 111,\n",
              " 56,\n",
              " 92,\n",
              " 44,\n",
              " 59,\n",
              " 128,\n",
              " 72,\n",
              " 128,\n",
              " 94,\n",
              " 95,\n",
              " 95,\n",
              " 58,\n",
              " 116,\n",
              " 69,\n",
              " 56,\n",
              " 73,\n",
              " 60,\n",
              " 79,\n",
              " 127,\n",
              " 59,\n",
              " 63,\n",
              " 71,\n",
              " 86,\n",
              " 71,\n",
              " 110,\n",
              " 83,\n",
              " 79,\n",
              " 44,\n",
              " 77,\n",
              " 94,\n",
              " 59,\n",
              " 111,\n",
              " 53,\n",
              " 110,\n",
              " 110,\n",
              " 87,\n",
              " 94,\n",
              " 88,\n",
              " 67,\n",
              " 125,\n",
              " 88,\n",
              " 95,\n",
              " 81,\n",
              " 60,\n",
              " 83,\n",
              " 86,\n",
              " 112,\n",
              " 51,\n",
              " 128,\n",
              " 91,\n",
              " 51,\n",
              " 59,\n",
              " 123,\n",
              " 53,\n",
              " 44,\n",
              " 113,\n",
              " 127,\n",
              " 51,\n",
              " 53,\n",
              " 86,\n",
              " 53,\n",
              " 121,\n",
              " 124,\n",
              " 92,\n",
              " 63,\n",
              " 121,\n",
              " 53,\n",
              " 80,\n",
              " 44,\n",
              " 95,\n",
              " 86,\n",
              " 90,\n",
              " 90,\n",
              " 91,\n",
              " 87,\n",
              " 114,\n",
              " 120,\n",
              " 54,\n",
              " 73,\n",
              " 60,\n",
              " 58,\n",
              " 59,\n",
              " 71,\n",
              " 53,\n",
              " 88,\n",
              " 43,\n",
              " 94,\n",
              " 77,\n",
              " 94,\n",
              " 77,\n",
              " 95,\n",
              " 53,\n",
              " 80,\n",
              " 71,\n",
              " 86,\n",
              " 111,\n",
              " 123,\n",
              " 88,\n",
              " 98,\n",
              " 72,\n",
              " 119,\n",
              " 54,\n",
              " 91,\n",
              " 53,\n",
              " 79,\n",
              " 53,\n",
              " 44,\n",
              " 126,\n",
              " 60,\n",
              " 95,\n",
              " 53,\n",
              " 95,\n",
              " 126,\n",
              " 121,\n",
              " 94,\n",
              " 54,\n",
              " 56,\n",
              " 59,\n",
              " 121,\n",
              " 61,\n",
              " 117,\n",
              " 54,\n",
              " 91,\n",
              " 69,\n",
              " 69,\n",
              " 95,\n",
              " 121,\n",
              " 94,\n",
              " 90,\n",
              " 59,\n",
              " 104,\n",
              " 73,\n",
              " 86,\n",
              " 121,\n",
              " 124,\n",
              " 79,\n",
              " 94,\n",
              " 87,\n",
              " 51,\n",
              " 123,\n",
              " 44,\n",
              " 120,\n",
              " 54,\n",
              " 116,\n",
              " 63,\n",
              " 94,\n",
              " 58,\n",
              " 114,\n",
              " 53,\n",
              " 87,\n",
              " 69,\n",
              " 69,\n",
              " 95,\n",
              " 121,\n",
              " 127,\n",
              " 95,\n",
              " 53,\n",
              " 80,\n",
              " 73,\n",
              " 88,\n",
              " 112,\n",
              " 67,\n",
              " 54,\n",
              " 91,\n",
              " 58,\n",
              " 58,\n",
              " 61,\n",
              " 90,\n",
              " 53,\n",
              " 65,\n",
              " 60,\n",
              " 51,\n",
              " 123,\n",
              " 44,\n",
              " 126,\n",
              " 60,\n",
              " 95,\n",
              " 53,\n",
              " 95,\n",
              " 53,\n",
              " 65,\n",
              " 94,\n",
              " 110,\n",
              " 56,\n",
              " 91,\n",
              " 73,\n",
              " 126,\n",
              " 83,\n",
              " 86,\n",
              " 89,\n",
              " 54,\n",
              " 71,\n",
              " 79,\n",
              " 121,\n",
              " 120,\n",
              " 59,\n",
              " 125,\n",
              " 54,\n",
              " 88,\n",
              " 59,\n",
              " 128,\n",
              " 60,\n",
              " 56,\n",
              " 86,\n",
              " 111,\n",
              " 79,\n",
              " 44,\n",
              " 105,\n",
              " 84,\n",
              " 91,\n",
              " 67,\n",
              " 124,\n",
              " 88,\n",
              " 53,\n",
              " 54,\n",
              " 101,\n",
              " 128,\n",
              " 105,\n",
              " 84,\n",
              " 114,\n",
              " 87,\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# デコーディング\n",
        "## 索引(インデックス)から単語の列（もしくは文字列）に変換すること"
      ],
      "metadata": {
        "id": "d5-ic9UuuhXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode(idx):\n",
        "  itoc = {i:c for (i, c) in enumerate(sorted(set(texts)))}\n",
        "  return ''.join([itoc[i] for i in idx])\n",
        "\n",
        "decoded = decode(encoded_txt[:10])"
      ],
      "metadata": {
        "id": "K1vSnP0g_1oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(\"lambda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNyB0qva3ASY",
        "outputId": "df641bba-d683-4f7c-fefa-f81f54c80174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lambdas\n",
            "*******\n",
            "\n",
            "   lambda_expr ::= \"lambda\" [parameter_list] \":\" expression\n",
            "\n",
            "Lambda expressions (sometimes called lambda forms) are used to create\n",
            "anonymous functions. The expression \"lambda parameters: expression\"\n",
            "yields a function object.  The unnamed object behaves like a function\n",
            "object defined with:\n",
            "\n",
            "   def <lambda>(parameters):\n",
            "       return expression\n",
            "\n",
            "See section Function definitions for the syntax of parameter lists.\n",
            "Note that functions created with lambda expressions cannot contain\n",
            "statements or annotations.\n",
            "\n",
            "Related help topics: FUNCTIONS\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(\"lambda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2js4cyG3olW",
        "outputId": "d3df48a0-44f5-450d-a356-e638befe9a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lambdas\n",
            "*******\n",
            "\n",
            "   lambda_expr ::= \"lambda\" [parameter_list] \":\" expression\n",
            "\n",
            "Lambda expressions (sometimes called lambda forms) are used to create\n",
            "anonymous functions. The expression \"lambda parameters: expression\"\n",
            "yields a function object.  The unnamed object behaves like a function\n",
            "object defined with:\n",
            "\n",
            "   def <lambda>(parameters):\n",
            "       return expression\n",
            "\n",
            "See section Function definitions for the syntax of parameter lists.\n",
            "Note that functions created with lambda expressions cannot contain\n",
            "statements or annotations.\n",
            "\n",
            "Related help topics: FUNCTIONS\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ctoi = {c:i for (i, c) in enumerate(sorted(set(texts)))}\n",
        "itoc = {i:c for (i, c) in enumerate(sorted(set(texts)))}"
      ],
      "metadata": {
        "id": "vOcAyYxKBA28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode = lambda s:[ctoi[c] for c in s]\n",
        "decode = lambda l:''.join([itoc[i] for i in l])"
      ],
      "metadata": {
        "id": "YT3Wdlp0LRtr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decode(encode(texts[:10]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "U34jsBZRLqHR",
        "outputId": "3634ca77-b680-40ad-815d-3fb03612b9ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'わがはいはねこである'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 訓練データと検証データの作成（Pytorchのtensor型に変換してsplit）"
      ],
      "metadata": {
        "id": "ojqS8X7uMB2o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "data = torch.tensor(encode(texts), dtype=torch.long)"
      ],
      "metadata": {
        "id": "00pcFXOYLubG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bszDcQqRnrN",
        "outputId": "1eaedfb4-5b5f-443b-c0ec-f41c4391cfd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([395470])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:50]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMATuTgmSCQn",
        "outputId": "6ca8060d-f3ec-4c2b-c134-a70fa4edf4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([126,  60,  95,  53,  95,  93,  67,  87,  51, 123,  44,  90, 110,  56,\n",
              "         95, 110,  80,  90,  53,  44,  89,  67,  87,  54, 110, 124,  79,  59,\n",
              "         88, 128,  88,  65, 128,  88,  54,  60,  84,  59,  92,  44,  90,  91,\n",
              "         87, 114,  54,  73,  64, 121,  53,  72])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "test_data = data[n:]"
      ],
      "metadata": {
        "id": "1MbC46mcSDRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data), len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNPGcRmGSV_Q",
        "outputId": "bfbd0507-1e63-4a15-fabc-fa7331fa3bd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "355923 39547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 大規模言語モデル（LLM: Large Language Models）の本質\n",
        "\n",
        "・次のトークン予測（今回は文字予測）タスク用データの準備\n",
        "\n",
        "・GPUを使った訓練"
      ],
      "metadata": {
        "id": "KFBOOohxUZjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "train_data[:block_size+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDooktJgfD_c",
        "outputId": "5b460d49-85e7-4ea8-9689-276bd854f548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([126,  60,  95,  53,  95,  93,  67,  87,  51])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[:block_size+1]\n",
        "y = train_data[1:block_size+1]\n",
        "\n",
        "for t in range(block_size):\n",
        "  context = x[:t+1]\n",
        "  target = y[t].item() #pytorch tutorial\n",
        "  print(f\"入力：{context}, 出力:{target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0DGk7eQgi76",
        "outputId": "ee8ffd2b-c2f1-4144-bc9d-e1004c55075e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "入力：tensor([126]), 出力:60\n",
            "入力：tensor([126,  60]), 出力:95\n",
            "入力：tensor([126,  60,  95]), 出力:53\n",
            "入力：tensor([126,  60,  95,  53]), 出力:95\n",
            "入力：tensor([126,  60,  95,  53,  95]), 出力:93\n",
            "入力：tensor([126,  60,  95,  53,  95,  93]), 出力:67\n",
            "入力：tensor([126,  60,  95,  53,  95,  93,  67]), 出力:87\n",
            "入力：tensor([126,  60,  95,  53,  95,  93,  67,  87]), 出力:51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "HfBzTvXtjKZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "batch_size = 4\n",
        "torch.manual_seed(825)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YijKAQehjiCe",
        "outputId": "879f0ec9-6600-4379-ca60-e8488d819106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c6cc133c270>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(len(data) - block_size, (batch_size, ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwfoaAaxkfwd",
        "outputId": "ddd246c8-d7ee-4b76-a054-a71e8726656b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([105183,  23016, 179976, 116576])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack([torch.tensor([1,2,3]), torch.tensor([4,5,6])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZH1fH_EukmT5",
        "outputId": "6d236422-9431-4157-df5c-89dc50f3d52f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_batch(split):\n",
        "  \"\"\" ミニバッチを取得\n",
        "    split(str): train or test\n",
        "  \"\"\"\n",
        "  data = train_data if split == 'train' else test_data\n",
        "  ix = torch.randint(len(data) - block_size, (batch_size, ))\n",
        "  x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "  y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "  return x.to(device), y.to(device)"
      ],
      "metadata": {
        "id": "AKJQ3TlPjmRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train')"
      ],
      "metadata": {
        "id": "UfShApD0lIim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uSO-W8rlLRE",
        "outputId": "608ea391-6076-48f2-8fa3-884365ebe432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "474ZL5cFlL6B",
        "outputId": "fc222b9c-59cc-4908-ecac-59a8511b2a9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evDKm7qNlM4d",
        "outputId": "76955dfb-c1a1-42c6-cef8-d227f3ab3e6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 71,  61,  90, 121, 121, 128, 110,  88],\n",
              "        [128,  94,  59, 128,  59,  63, 127,  88],\n",
              "        [114, 108,  63, 127,  71, 119,  54,  61],\n",
              "        [131,  88, 114,  81,  51,  66, 121, 124]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yb"
      ],
      "metadata": {
        "id": "9jcFgSZ9lQr0",
        "outputId": "67c9be4c-abc9-4515-d762-cad514f0350c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 61,  90, 121, 121, 128, 110,  88,  53],\n",
              "        [ 94,  59, 128,  59,  63, 127,  88,  83],\n",
              "        [108,  63, 127,  71, 119,  54,  61, 119],\n",
              "        [ 88, 114,  81,  51,  66, 121, 124,  79]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 最も単純な2-gramモデルを訓練\n",
        "\n",
        "* nn.Moduleクラスを継承"
      ],
      "metadata": {
        "id": "YRU6wB1LOQBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(set(texts))\n",
        "vocab_size"
      ],
      "metadata": {
        "id": "cietzlVxlU60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f51ae10-1fcd-4640-9884-d17d70b9fe52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "673"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(set([i.item() for i in data]))\n",
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgZUiqdlPrZO",
        "outputId": "0e0f8f6a-4fb2-4d4f-8797-8e416f31045f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "673"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vmypRfuPJgR",
        "outputId": "64bc3f44-d001-4ed6-ec0e-31941d8a0282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([126,  60,  95,  53,  95,  93,  67,  87,  51, 123])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[:10]"
      ],
      "metadata": {
        "id": "S92t2rnDQKgX",
        "outputId": "2e057f74-9adb-4d67-cf52-73d67f7762fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'わがはいはねこである'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "Ukw6SjtEQLsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size).to(device)\n",
        "\n",
        "  def forward(self, idx, targets):\n",
        "    logits = self.token_embedding_table(idx)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "1YmgMnEppxvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = BigramLanguageModel(vocab_size)"
      ],
      "metadata": {
        "id": "Ls7rYTe9sCtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = m(xb, yb)"
      ],
      "metadata": {
        "id": "By4tk0wHsGJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9UcysZgsuHU",
        "outputId": "dd7290c1-88f9-4310-9d4c-6f48fcd4e1d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoM0XA8vtLgX",
        "outputId": "b90ed74d-0ccd-4d91-a2dd-0949f530c62c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 673])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu4SMR81sXDY",
        "outputId": "12949aa6-9568-4e5c-90e7-8c5971deb7df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0238,  0.4836, -1.2794,  ..., -0.8560,  0.6900, -1.2224],\n",
              "         [ 0.0098, -0.4977, -1.6767,  ...,  0.8834,  1.0018,  1.7431],\n",
              "         [ 1.9313,  1.3786, -1.0101,  ...,  0.3446,  1.2663,  0.2734],\n",
              "         ...,\n",
              "         [-1.5288, -0.5065, -1.2861,  ..., -1.0272, -0.7021,  1.1295],\n",
              "         [-0.5599,  0.2612, -1.7893,  ..., -0.3391,  0.0912,  0.4208],\n",
              "         [ 1.9650, -0.8913,  0.5921,  ...,  0.3632,  0.2208, -0.8550]],\n",
              "\n",
              "        [[-1.5288, -0.5065, -1.2861,  ..., -1.0272, -0.7021,  1.1295],\n",
              "         [ 1.2050,  0.7333,  0.0316,  ..., -0.5102,  0.2448, -0.8419],\n",
              "         [ 0.8267,  0.2788, -2.6456,  ..., -1.5758, -1.2271,  0.5149],\n",
              "         ...,\n",
              "         [ 0.5166, -0.0446,  0.9283,  ..., -1.3275,  1.5114,  0.8338],\n",
              "         [-0.0405, -0.6578,  0.7340,  ...,  1.2118, -0.3390, -1.0983],\n",
              "         [ 1.9650, -0.8913,  0.5921,  ...,  0.3632,  0.2208, -0.8550]],\n",
              "\n",
              "        [[ 0.5672,  0.4672, -0.5015,  ...,  1.0559,  0.2809,  1.2613],\n",
              "         [-1.5352,  0.7513, -1.1041,  ...,  0.1750,  1.2243,  1.8182],\n",
              "         [ 0.5166, -0.0446,  0.9283,  ..., -1.3275,  1.5114,  0.8338],\n",
              "         ...,\n",
              "         [ 0.8955,  1.0258,  0.8024,  ..., -0.4821,  0.0963, -0.8880],\n",
              "         [ 0.4206,  0.3900, -0.6126,  ...,  0.1046,  1.5044,  1.3615],\n",
              "         [ 0.0098, -0.4977, -1.6767,  ...,  0.8834,  1.0018,  1.7431]],\n",
              "\n",
              "        [[-0.7545,  0.6255,  0.6126,  ..., -0.8699, -0.0370, -0.1951],\n",
              "         [ 1.9650, -0.8913,  0.5921,  ...,  0.3632,  0.2208, -0.8550],\n",
              "         [ 0.5672,  0.4672, -0.5015,  ...,  1.0559,  0.2809,  1.2613],\n",
              "         ...,\n",
              "         [-0.2498,  0.2651,  0.0832,  ..., -0.2178, -1.6653,  0.2897],\n",
              "         [-2.0493,  1.9546,  0.5341,  ..., -1.2952,  2.7026, -0.3624],\n",
              "         [ 1.1572, -0.2695,  0.6918,  ...,  1.1985,  0.3984, -0.5372]]],\n",
              "       device='cuda:0', grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(nn.Module):\n",
        "  def __init__(self, vocab_size):\n",
        "    super().__init__()\n",
        "    self.token_embedding_table = nn.Embedding(vocab_size, vocab_size).to(device)\n",
        "\n",
        "  def forward(self, idx, targets=None):\n",
        "    logits = self.token_embedding_table(idx)\n",
        "    if targets is None:\n",
        "      loss = None\n",
        "    else:\n",
        "      B, T, C = logits.shape\n",
        "      logits = logits.view(-1, C)\n",
        "      targets = targets.view(-1)\n",
        "      loss = F.cross_entropy(logits, targets)\n",
        "    return logits, loss\n",
        "\n",
        "  def generate(self, idx, max_tokens):\n",
        "    for _ in range(max_tokens):\n",
        "      # 予測\n",
        "      logits, loss = self(idx)\n",
        "      # 最後のタイムステップ（文字）にフォーカス\n",
        "      logits = logits[:, -1, :] # (B, C)\n",
        "      probs = F.softmax(logits, dim=-1)\n",
        "      idx_next = torch.multinomial(probs, num_samples=1)\n",
        "      idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "    return idx"
      ],
      "metadata": {
        "id": "BFcmIFd5srTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel(vocab_size)"
      ],
      "metadata": {
        "id": "wU4hJUouvRQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = model.to(device)"
      ],
      "metadata": {
        "id": "gQmRXXFG0Esq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits, loss = m(xb, yb)"
      ],
      "metadata": {
        "id": "W7D0ekhp0H-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-SLybEZ0J1M",
        "outputId": "622775c9-3177-42d2-840c-ed2ed7611ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 673])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftiDFeTk0N2C",
        "outputId": "7c38118e-471f-400b-8685-743cea117f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(7.2310, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = torch.zeros((1, 1), dtype=torch.long).to(device)"
      ],
      "metadata": {
        "id": "yVt15ftu0QL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNIAMoN_0YGy",
        "outputId": "66d7fd60-7eba-4213-c2c2-b8bdf1a234ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(sorted(set(texts)))[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "G8CY3K_D0YZ8",
        "outputId": "f691fe1e-e11f-49cb-e15b-652a0ed49d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode(m.generate(idx, max_tokens=10)[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5aj0AjY20jbY",
        "outputId": "c1285f6d-d95c-426d-a6db-8b10288e5a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 談淋に這d箝客愧事政'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 訓練コード"
      ],
      "metadata": {
        "id": "6heyoyUJf6VW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_iters = 20000\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "yrDbHiPd0qQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=32"
      ],
      "metadata": {
        "id": "-xLXQwkggdgw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_iters = 200\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  m.eval()\n",
        "  for split in ['train', 'test']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y = get_batch(split)\n",
        "      logits, loss = m(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  m.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "FatYEMEqpnbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_interval = 300\n",
        "for steps in range(max_iters):\n",
        "  if steps % eval_interval == 0:\n",
        "    losses = estimate_loss()\n",
        "    print(f\"step: {steps}, train_loss: {losses['train']:.4f}, test loss {losses['test']:.4f}\")\n",
        "  xb, yb = get_batch(\"train\")\n",
        "  logits, loss = m(xb, yb) #推論\n",
        "  optimizer.zero_grad(set_to_none=True)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  if steps % 1000 == 0:\n",
        "    print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inGR00ftgf_i",
        "outputId": "95aef42f-03c9-4887-9600-c03429c3aa52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, train_loss: 7.0100, test loss 6.9989\n",
            "tensor(6.8862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 300, train_loss: 6.6630, test loss 6.6591\n",
            "step: 600, train_loss: 6.3391, test loss 6.3233\n",
            "step: 900, train_loss: 6.0144, test loss 6.0115\n",
            "tensor(5.8402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 1200, train_loss: 5.7190, test loss 5.7221\n",
            "step: 1500, train_loss: 5.4440, test loss 5.4560\n",
            "step: 1800, train_loss: 5.2065, test loss 5.2191\n",
            "tensor(5.0970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 2100, train_loss: 4.9757, test loss 5.0008\n",
            "step: 2400, train_loss: 4.7806, test loss 4.8013\n",
            "step: 2700, train_loss: 4.6062, test loss 4.6253\n",
            "step: 3000, train_loss: 4.4359, test loss 4.4631\n",
            "tensor(4.3844, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 3300, train_loss: 4.3060, test loss 4.3313\n",
            "step: 3600, train_loss: 4.1808, test loss 4.2062\n",
            "step: 3900, train_loss: 4.0700, test loss 4.1007\n",
            "tensor(4.1491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 4200, train_loss: 3.9889, test loss 4.0154\n",
            "step: 4500, train_loss: 3.8966, test loss 3.9437\n",
            "step: 4800, train_loss: 3.8254, test loss 3.8788\n",
            "tensor(3.8606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 5100, train_loss: 3.7676, test loss 3.8099\n",
            "step: 5400, train_loss: 3.7169, test loss 3.7648\n",
            "step: 5700, train_loss: 3.6768, test loss 3.7120\n",
            "step: 6000, train_loss: 3.6181, test loss 3.6809\n",
            "tensor(3.6429, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 6300, train_loss: 3.6005, test loss 3.6492\n",
            "step: 6600, train_loss: 3.5690, test loss 3.6264\n",
            "step: 6900, train_loss: 3.5457, test loss 3.5948\n",
            "tensor(3.4354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 7200, train_loss: 3.5297, test loss 3.5840\n",
            "step: 7500, train_loss: 3.4957, test loss 3.5481\n",
            "step: 7800, train_loss: 3.4803, test loss 3.5350\n",
            "tensor(3.4893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 8100, train_loss: 3.4811, test loss 3.5079\n",
            "step: 8400, train_loss: 3.4567, test loss 3.5096\n",
            "step: 8700, train_loss: 3.4407, test loss 3.4911\n",
            "step: 9000, train_loss: 3.4388, test loss 3.4808\n",
            "tensor(3.5042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 9300, train_loss: 3.4300, test loss 3.4889\n",
            "step: 9600, train_loss: 3.4175, test loss 3.4796\n",
            "step: 9900, train_loss: 3.4091, test loss 3.4612\n",
            "tensor(3.4515, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 10200, train_loss: 3.4107, test loss 3.4657\n",
            "step: 10500, train_loss: 3.3904, test loss 3.4488\n",
            "step: 10800, train_loss: 3.3951, test loss 3.4520\n",
            "tensor(3.4233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 11100, train_loss: 3.3959, test loss 3.4544\n",
            "step: 11400, train_loss: 3.3943, test loss 3.4526\n",
            "step: 11700, train_loss: 3.3847, test loss 3.4485\n",
            "step: 12000, train_loss: 3.3782, test loss 3.4399\n",
            "tensor(3.2936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 12300, train_loss: 3.3846, test loss 3.4382\n",
            "step: 12600, train_loss: 3.3822, test loss 3.4418\n",
            "step: 12900, train_loss: 3.3759, test loss 3.4336\n",
            "tensor(3.4216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 13200, train_loss: 3.3689, test loss 3.4338\n",
            "step: 13500, train_loss: 3.3651, test loss 3.4244\n",
            "step: 13800, train_loss: 3.3600, test loss 3.4255\n",
            "tensor(3.3892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 14100, train_loss: 3.3663, test loss 3.4381\n",
            "step: 14400, train_loss: 3.3656, test loss 3.4217\n",
            "step: 14700, train_loss: 3.3612, test loss 3.4224\n",
            "step: 15000, train_loss: 3.3669, test loss 3.4333\n",
            "tensor(3.3481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 15300, train_loss: 3.3664, test loss 3.4188\n",
            "step: 15600, train_loss: 3.3596, test loss 3.4256\n",
            "step: 15900, train_loss: 3.3580, test loss 3.4204\n",
            "tensor(3.2611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 16200, train_loss: 3.3614, test loss 3.4088\n",
            "step: 16500, train_loss: 3.3537, test loss 3.4255\n",
            "step: 16800, train_loss: 3.3555, test loss 3.4039\n",
            "tensor(3.3867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 17100, train_loss: 3.3518, test loss 3.4272\n",
            "step: 17400, train_loss: 3.3508, test loss 3.4176\n",
            "step: 17700, train_loss: 3.3617, test loss 3.4239\n",
            "step: 18000, train_loss: 3.3558, test loss 3.4104\n",
            "tensor(3.3839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 18300, train_loss: 3.3479, test loss 3.4179\n",
            "step: 18600, train_loss: 3.3607, test loss 3.4221\n",
            "step: 18900, train_loss: 3.3449, test loss 3.4126\n",
            "tensor(3.3851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "step: 19200, train_loss: 3.3546, test loss 3.4151\n",
            "step: 19500, train_loss: 3.3503, test loss 3.4146\n",
            "step: 19800, train_loss: 3.3478, test loss 3.4223\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decode(m.generate(idx, max_tokens=100)[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8wsReHiTg6-R",
        "outputId": "1c2ef201-b83e-405d-d754-c5898572295f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 易倆事m痞忽度学きたくにからいたずかりもうぶんをとこんざしいろうしない。かにてきっていでこにしへでにんとから、て、けんかげんじまれれむかもおものでするべかえてもって、ひろいた。それだけのおうにがいるた'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts[9000:10000]"
      ],
      "metadata": {
        "id": "Yv1waazthCLA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "outputId": "e23699f4-41a3-4417-b009-8f7e7b163a5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'はらのたしになるもんか」かれはだいにかんしゃくにさわったようすで、かんちくをそいだようなみみをしきりとぴくつかせてあららかにたちさった。わがはいがくるまやのくろとちきになったのはこれからである。そのごわがはいはたびたびくろとかいこうする。かいこうするごとにかれはくるまやそうとうのきえんをはく。さきにわがはいがみみにしたというふとくじけんもじつはくろからきいたのである。あるるひれいのごとくわがはいとくろはあたたかいちゃはたけのなかでねころびながらいろいろざつだんをしていると、かれはいつものじまんはなしをさもあたらしそうにくりかえしたあとで、わがはいにむかってしたのごとくしつもんした。「ごめえはいままでにねずみをなんひきとったことがある」ちしきはくろよりもよほどはったつしているつもりだがわんりょくとゆうきとにいたってはとうていくろのひかくにはならないとかくごはしていたものの、このといにせっしたるときは、さすがにきまりがよくはなかった。けれどもじじつはじじつで詐るわけにはいかないから、わがはいは「じつはとろうとろうとおもってまだとらない」とこたえた。くろはかれのはなのさきからぴんと突張っているながいひげをびりびりとふるわせてひじょうにわらった。がんらいくろはじまんをするたけにどこかたりないところがあって、かれのきえんをかんしんしたようにいんこうをころころならしてきんちょうしていればはなはだぎょしやすいねこである。わがはいはかれとこんづけになってからじかにこのこきゅうをのみこんだからこのばあいにもなまじいおのれれをべんごしてますますけいせいをわるくするのもぐである、いっそのことかれにじぶんのてがらばなしをしゃべらしてごちゃをにごすにわかくはないとしあんをさだめた。そこでおとなしく「きみなどはとしがとしであるからだいぶとったろう」とそそのかしてみた。かぜんかれは墻壁のけつしょにとっかんしてきた。「たんとでもねえがさんよんじゅうはとったろう」とはとくいげなるかれのこたえであった。かれはなおかたりをつづけて「ねずみのひゃくやにひゃくはいちにんでいつでもひきうけるがいたちってえやつはてにあわねえ。いちどいたちにむかってひどいめにあった」「へえなるほど」とあいづちをうつ。くろはおおきなめをぱちつかせていう。「きょねんのだいそうじのときだ。うちのていしゅがせっかいのふくろをもって椽のし'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Attentionの考え方\n",
        "0. 言語モデルで現在のトークン（過去のトークンの平均）をfor文で単純に得る方法\n",
        "1. 言語モデルで現在のトークンが持っている情報を効率的に得る方法 (attentionではない場合（平均））\n",
        "2. Attention(Key, Query, Value)機構を効率的に得る方法"
      ],
      "metadata": {
        "id": "34auqg1YTLLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "torch.manual_seed(826)\n",
        "\n",
        "B, T, C = 4, 8, 2\n",
        "x = torch.randn(B, T, C)\n",
        "x.shape"
      ],
      "metadata": {
        "id": "ZMOPZlm6hbdC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6890ec-af59-404c-afe1-b0b9aec82d60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "わ→が→は→い→は→ね→こ→で→あ→る"
      ],
      "metadata": {
        "id": "sBGcE6a7fT28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = torch.zeros((B, T, C))\n",
        "for b in range(B):\n",
        "  for t in range(T):\n",
        "    xprev = x[b, :t+1] # (t, C)\n",
        "    xbow[b, t] = torch.mean(xprev, 0)\n",
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCeWSOs7TS4P",
        "outputId": "c5653d33-ea08-47a0-b09a-278977d79584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3604, -1.5006],\n",
              "        [ 0.7338, -0.6960],\n",
              "        [ 0.5539, -0.1388],\n",
              "        [ 0.3351,  0.2609],\n",
              "        [ 0.1492,  0.3077],\n",
              "        [ 0.0892,  0.1931],\n",
              "        [-0.0351,  0.1505],\n",
              "        [ 0.0029,  0.3566]])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o = torch.ones(3,3)\n",
        "a = torch.tril(o)"
      ],
      "metadata": {
        "id": "QyqpGZVXmZy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = a / a.sum(1, keepdim=True)"
      ],
      "metadata": {
        "id": "4p5FPeBpm7qJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctFvRkp7naBV",
        "outputId": "bbe9d125-6e44-4d42-8cf2-56420bd4cb86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = torch.randint(0, 10, (3,2)).float()\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaQnxnPGmfn5",
        "outputId": "43e547f4-8065-41a3-c4db-9de2173749e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8., 5.],\n",
              "        [5., 0.],\n",
              "        [7., 3.]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a@b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18nfq9WJmwmU",
        "outputId": "e912252c-26e9-4820-809b-25ee4f0f61de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[8.0000, 5.0000],\n",
              "        [6.5000, 2.5000],\n",
              "        [6.6667, 2.6667]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o = torch.ones(T,T)\n",
        "a = torch.tril(o)\n",
        "w = a/ a.sum(1, keepdim=True)\n",
        "xbow2 = w @ x"
      ],
      "metadata": {
        "id": "bhQY2ictnAY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoBzhfS2nyhx",
        "outputId": "f832b822-e834-4392-9333-42ea84774a71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3604, -1.5006],\n",
              "        [ 0.7338, -0.6960],\n",
              "        [ 0.5539, -0.1388],\n",
              "        [ 0.3351,  0.2609],\n",
              "        [ 0.1492,  0.3077],\n",
              "        [ 0.0892,  0.1931],\n",
              "        [-0.0351,  0.1505],\n",
              "        [ 0.0029,  0.3566]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xbow[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GagV8uobnzxQ",
        "outputId": "bd3ebdbc-2c11-48e6-a12d-2dd1c528ef58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3604, -1.5006],\n",
              "        [ 0.7338, -0.6960],\n",
              "        [ 0.5539, -0.1388],\n",
              "        [ 0.3351,  0.2609],\n",
              "        [ 0.1492,  0.3077],\n",
              "        [ 0.0892,  0.1931],\n",
              "        [-0.0351,  0.1505],\n",
              "        [ 0.0029,  0.3566]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.allclose(xbow, xbow2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFMBxlfan1Mp",
        "outputId": "3b09147d-4ef4-4ad7-e9ad-23c27111a40a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=1)\n",
        "xbow3 = wei @ x\n",
        "torch.allclose(xbow, xbow3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeevfYVvqsil",
        "outputId": "a3e8f6d4-7294-4117-9832-88cfc8069e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiHfiI_zWjrA",
        "outputId": "57dfa0b4-a295-46a5-eb80-ef59387ab8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
              "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
              "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
              "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self-Attention\n",
        "* 単一ヘッドを持つアテンションの実装\n",
        "* <u>すべての単語（文字）はその前までの単語（文字）の情報をデータによって変わる重みを考慮する</u>\n",
        "* Query：何を探しているか、 Key: それぞれの単語（文字）が何の情報を持っているか、Value：最終出力対象の材料（ベクトルの基底）\n",
        "→言い換えると、「Query（=問い合わせ）の各トークンに対応する、Value(=値)の重要度をKey（=鍵）を使って取り出し、Vの行ベクトルの線形結合として出力したもの」がSelf-Attentionである（参考：[Transformer: アテンションの計算式の意味を数理的に理解する](https://zenn.dev/bilzard/articles/49d453c7809be3)）\n",
        "\n",
        "$$\n",
        "Attention(Q, K, V) = softmax(\\frac{QK^T}{\\sqrt{d_k}})V\n",
        "$$\n"
      ],
      "metadata": {
        "id": "veZoIch2pp8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "torch.manual_seed(827)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqWakJa-V3T_",
        "outputId": "53e09974-55ad-49a8-aa62-31a9baa13060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c6cc133c270>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B, T, C = 4, 8, 32\n",
        "x = torch.randn(B, T, C)\n",
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0HmP4qRV9Zg",
        "outputId": "b80fb970-1e26-4a87-a8e1-32234689edb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tril = torch.tril(torch.ones(T, T))\n",
        "head_size = 16\n",
        "query = nn.Linear(C, head_size, bias=False) # input: 32, output 16 -> 4, 8, 16\n",
        "key = nn.Linear(C, head_size, bias=False)\n",
        "value = nn.Linear(C, head_size, bias=False)"
      ],
      "metadata": {
        "id": "HQC5HW5oWaHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q = query(x)\n",
        "k = key(x)\n",
        "v = value(x)"
      ],
      "metadata": {
        "id": "DolGumkHWa3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6feU0_6SW1IT",
        "outputId": "3543dd81-1e3f-40d0-d23d-7f1956a3127e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iT-nd36NW2pv",
        "outputId": "11544782-4f2c-4cfa-ece4-5548172f3c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k.transpose(-2, -1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhpiH76ZW_Ny",
        "outputId": "b82c444b-81b5-4397-f26a-3b5b59b0c02c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 16, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(q@k.transpose(-2, -1)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CEOCiloWu73",
        "outputId": "5c7a7fb6-a8f2-4f19-ba63-adb61d136b1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d_k = head_size\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "m27BgL3KyoGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d_k ** -0.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdSSih49yzBj",
        "outputId": "965eb642-a88f-49a6-d684-f64fbc5b24a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1/np.sqrt(d_k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqIrUGjWy0m4",
        "outputId": "c795552b-13cf-4cdf-8c29-00677f7a40e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = q@k.transpose(-2, -1) * (1/np.sqrt(d_k))\n",
        "# wei = torch.zeros((T, T))\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "wei = F.softmax(wei, dim=1)\n",
        "xbow4 = wei @ v"
      ],
      "metadata": {
        "id": "I3nEiTe3Vzmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow4[0]"
      ],
      "metadata": {
        "id": "dNDVZjb6XyVt",
        "outputId": "6e64370e-40f0-4ce8-f34f-114953a2f9d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1200, -0.1601,  0.2589,  0.0208, -0.0648,  0.0027,  0.0125, -0.1319,\n",
              "          0.1030,  0.1593,  0.0765,  0.1557, -0.0718,  0.0147, -0.2215,  0.0568],\n",
              "        [-0.0108, -0.0218,  0.0766, -0.0081,  0.0053,  0.0279, -0.0353, -0.0339,\n",
              "          0.0805,  0.0615,  0.0482,  0.0764, -0.0157, -0.0137, -0.1084,  0.0214],\n",
              "        [ 0.2832,  0.2433,  0.1711, -0.1769,  0.2118,  0.3321, -0.3928,  0.1137,\n",
              "          0.6217,  0.2233,  0.2119,  0.2911,  0.2739,  0.2648, -0.2952, -0.0544],\n",
              "        [ 0.1207,  0.4009,  0.3361, -0.0288,  0.2656,  0.3648, -0.3785,  0.1752,\n",
              "          0.4593, -0.0371,  0.1876, -0.2080,  0.3474,  0.5154, -0.2482,  0.0052],\n",
              "        [ 0.0626,  0.4859,  0.1691, -0.0185,  0.1479,  0.3895, -0.4248,  0.1886,\n",
              "          0.4691, -0.1431,  0.1500, -0.3176,  0.1735,  0.2553, -0.3713,  0.2097],\n",
              "        [ 0.3021, -0.1055, -0.0995, -0.3695,  0.3832,  0.2057,  0.3904,  0.0583,\n",
              "         -0.0238, -0.3994, -0.1742, -0.3680,  0.6366,  0.2916, -0.0166,  0.0525],\n",
              "        [ 0.1683,  0.0149, -0.2770,  0.4663, -1.4919,  0.1182,  0.1066,  0.6689,\n",
              "         -0.0624, -0.5021, -0.7376,  0.0089, -0.0435,  0.3704,  0.5412,  0.7414],\n",
              "        [ 0.0897, -0.5381,  0.6832,  0.6621,  0.0875,  0.7084,  0.6014,  0.4702,\n",
              "         -0.0131, -1.3260, -1.3083,  0.6857,  0.0101,  0.5063,  0.6744,  1.4533]],\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1,-0.2,-0.3,-0.2,0.5]), dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL_cROJrofJM",
        "outputId": "75ec030d-6acc-4b8d-9d43-dc35d97645ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1919, 0.1408, 0.1274, 0.2565, 0.2835])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.softmax(torch.tensor([0.1,-0.2,-0.3,-0.2,0.5])*8, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_CGcIltqcAA",
        "outputId": "3d18a694-74e0-48ce-9a57-93d50159166e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0388, 0.0035, 0.0016, 0.0035, 0.9525])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = torch.randn(B, T, d_k)\n",
        "k =torch.randn(B, T, d_k)"
      ],
      "metadata": {
        "id": "M0OZ5iuqzLQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = q @ k.transpose(-2,-1)*(1/np.sqrt(d_k))"
      ],
      "metadata": {
        "id": "rQ6HYO70zQCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0yg7ebpzTM3",
        "outputId": "fd96c0f7-a072-4b40-c017-c4cbc92881c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9375)"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHAoSD4PznGg",
        "outputId": "c0f799e6-1fb3-4f31-893c-ea73613285b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0436)"
            ]
          },
          "metadata": {},
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.var()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTr352DyzokA",
        "outputId": "3b964c3d-2c60-4353-d0d5-f5ada38039ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0410)"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 全コード(改善後）\n",
        "\n",
        "* positional encoding(まるごと体感したい、せとおおはし。 v.s. はしを使うのは難しい）\n",
        "* MultiHead attention（Scaled dot product attentionを複数結合）\n",
        "* dropoutを追加\n",
        "\n"
      ],
      "metadata": {
        "id": "lT6BOwNk35ff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# データ取得"
      ],
      "metadata": {
        "id": "tQgLYKwi_4LF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install janome\n",
        "!pip install jaconv\n",
        "\n",
        "import requests, bs4\n",
        "import re\n",
        "from janome.tokenizer import Tokenizer\n",
        "import jaconv\n",
        "import torch\n",
        "\n",
        "# よみがな（ひらがな）取得関数\n",
        "def get_yomigana(original_txt):\n",
        "  t = Tokenizer()\n",
        "  l = []\n",
        "  for w in t.tokenize(original_txt):\n",
        "    reading = w.reading\n",
        "    if  reading == '*':\n",
        "      l.append(w.base_form)\n",
        "    else:\n",
        "      l.append(reading)\n",
        "  hira = jaconv.kata2hira(''.join(l))\n",
        "  return hira\n",
        "\n",
        "# データ取得\n",
        "response = requests.get(\"https://www.aozora.gr.jp/cards/000148/files/789_14547.html\")\n",
        "soup = bs4.BeautifulSoup(response.content, \"html.parser\")\n",
        "elems = soup.select(\".main_text\")\n",
        "texts = ''.join([elm.text for elm in elems])\n",
        "pattern = re.compile(r\"\\n一\\n|\\r\\n|\\n|\\u3000\", re.MULTILINE | re.DOTALL)\n",
        "texts = re.sub(pattern, \"\", texts)\n",
        "texts = get_yomigana(texts)\n",
        "\n",
        "# すべてのユニークな文字（夏目漱石の「吾輩は猫であるに出現）\n",
        "chars = sorted(set(texts))\n",
        "ctoi = {c:i for (i, c) in enumerate(chars)}\n",
        "itoc = {i:c for (i, c) in enumerate(chars)}\n",
        "\n",
        "# エンコーダ・デコーダの定義\n",
        "encode = lambda s:[ctoi[c] for c in s]\n",
        "decode = lambda l:''.join([itoc[i] for i in l])\n",
        "\n",
        "# 訓練データ・検証用データの分け\n",
        "data = torch.tensor(encode(texts), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIA6nEd_8zLr",
        "outputId": "9973524f-5245-4e4c-92ca-4507935166d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: janome in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.10/dist-packages (0.3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yniY7cKF09W",
        "outputId": "3de7a471-8baf-4620-f92e-48bffcf30179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "673"
            ]
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モデル定義　→　訓練　→　1件推論"
      ],
      "metadata": {
        "id": "61xQ7JCr_6hY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# 結果再現用\n",
        "torch.manual_seed(827)\n",
        "\n",
        "# ハイパーパラメタ\n",
        "batch_size = 128 # いくつの独立したシーケンスを並列で扱うか\n",
        "block_size = 128 # コンテキストサイズ（チャンクサイズwhat is the maximum context length for predictions?\n",
        "max_iters = 1000\n",
        "eval_interval = 500\n",
        "learning_rate = 3e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 384\n",
        "n_head = 6\n",
        "n_layer = 6\n",
        "dropout = 0.2\n",
        "# ------------\n",
        "\n",
        "# ミニバッチ取得\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 入力サイズ (batch_size, time-step, channels)\n",
        "        # 出力しず (batch_size, time-step, head_size)\n",
        "        B,T,C = x.shape\n",
        "        k = self.key(x)   # (B,T,head_size)\n",
        "        q = self.query(x) # (B,T,head_size)\n",
        "        # アテンションスコアの計算(\"affinities:親和性\")\n",
        "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, head_size) @ (B, head_size, T) -> (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        # 値の重みつき集約（値からアテンションスコアに基づき対応する成分を取り出す）の実行\n",
        "        v = self.value(x) # (B,T,hs)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, hs) -> (B, T, hs)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" 並行して計算可能なセルフアテンションヘッド \"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" 非線形性をもつようにした全結合層 \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        # n_embd: embedding dimension, n_head\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "class GPTLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # 各トークンは、ルックアップテーブルから次のトークンのロジットを直接読み出す\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        x = self.blocks(x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx：(B, T)\n",
        "        for _ in range(max_new_tokens):\n",
        "            # idxを最後のブロック・サイズ・トークンにクロップする。\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # 推論\n",
        "            logits, loss = self(idx_cond)\n",
        "            # 最後のタイムステップのみに着目（言語モデルなので）\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # ソフトマックスを適用して確率を取得\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # 多項分布からサンプリング\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # シーケンスにサンプリングしたインデックスを追加\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "model = GPTLanguageModel()\n",
        "m = model.to(device)\n",
        "# モデルのパラメタ数を標準出力\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# 最適化関数は、AdamWを利用\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # eval_intervalの間隔ごとにlossの平均を評価する。\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, validation loss {losses['val']:.4f}\")\n",
        "\n",
        "    # ミニバッチを取得\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # 誤差逆伝播\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# サンプルを生成してみる。\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c4Z8bVdzqmw",
        "outputId": "3f4ad713-8940-4fdc-9fd8-0702e1f2a298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.207329 M parameters\n",
            "step 0: train loss 6.4870, validation loss 6.4869\n",
            "step 500: train loss 2.6419, validation loss 2.8797\n",
            "step 999: train loss 2.0711, validation loss 2.7962\n",
            " はっけんしつするくらいだ。これをしらずにむかっておこらんのである。しゅうめいはちきんじょうのやくぶふかないしゅつのかひかってくれればだくのはかっしである。ぬぼといおおいのずからかぜをひくだすにかにているにふうふうちがこんだけしかわきのけっかところでない。ただどころのためにねをひらいたしのはなしをして、はなしをすることはまたようにおもって、うまれごとくべしようかすが、いっしのくそをあげきしまわりのなかへはたかくけた。かおのしむかいそうとひぐるものところはろんぶんよりもないとへいぜんぼえてきだしたてぁい！としょうじがつまらあけて「しはそれじゃきみのなかむろはくくびぐるが、ぼりのまんぼうさんみずをねむくのでは、みやむをえずいぶんだけのらいたりで、すこぶるはたね。ひまのそれからはんへんぞんぶつのくらいなこころぼそいおんがすました。ぷれーとすおさめしをてそんこ」「かまわんとするんさ。そばめしをぼくらそんすってるんだな」くさいくんはへびめしめしくっている。迷亭はまったそうだとおもいおおやこのこえがする。迷にっせぬとおりなげんのほうへまいぎわに。「ともえかにていしゃさけごのないへいにすまんまよんです\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MV48pj9H4JP9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}